{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn import preprocessing\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDF = pd.read_csv('AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def features(df):\n",
    "    new_df = pd.DataFrame() \n",
    "    new_df['date'] = df['Date']\n",
    "    new_df['avg_prices'] = (df['Low'] + df['High']).apply(lambda x: x/2.0)\n",
    "    new_df['shifted_adj_close'] = df['Adj Close'].shift(-1)\n",
    "    #new_df['avg_close_week'] = df['Close'].rolling(window=5, center=False).mean()\n",
    "    #new_df['avg_close_month'] = df['Close'].rolling(window=21, center=False).mean()\n",
    "    #new_df['avg_close_quarter'] = df['Close'].rolling(window=84, center=False).mean()\n",
    "    #new_df['std_close_week'] = df['Close'].rolling(window=5, center=False).std()\n",
    "    #new_df['std_close_month'] = df['Close'].rolling(window=21, center=False).std()\n",
    "    #new_df['std_close_quarter'] = df['Close'].rolling(window=84, center=False).std()\n",
    "    new_df['open'] = df['Open']\n",
    "    new_df['high'] = df['High']\n",
    "    new_df['low'] = df['Low']\n",
    "    new_df['close'] = df['Close']\n",
    "    new_df['volume'] = df['Volume']\n",
    "    new_df = new_df.dropna(axis=0)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDF_new = features(dataDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "training ----> start : 2017/11/1\n",
    "validation ----> 2017/11/1 : 2018/4/1\n",
    "test ----> 2018/4/1 : end\n",
    "'''\n",
    "train_split_time = pd.datetime(2017,11,1)\n",
    "val_split_time = pd.datetime(2018,4,1)\n",
    "\n",
    "train_data = dataDF_new.loc[pd.to_datetime(dataDF_new['date']) <= train_split_time]\n",
    "val_data = dataDF_new.loc[(pd.to_datetime(dataDF_new['date']) > train_split_time) & (pd.to_datetime(dataDF_new['date']) <= val_split_time)]\n",
    "test_data = dataDF_new.loc[pd.to_datetime(dataDF_new['date']) > val_split_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data(train_data, test_data, predicted_days):\n",
    "    '''\n",
    "    this function takes train data and test data and return splitted normalized data and labels\n",
    "    '''\n",
    "    Open = train_data.open\n",
    "    high = train_data.high\n",
    "    low = train_data.low\n",
    "    close = train_data.close \n",
    "    volume = train_data.volume\n",
    "    avg_prices = train_data.avg_prices\n",
    "    adj_close = train_data.shifted_adj_close\n",
    "    #close_shifted = adj_close.shift(-predicted_days) \n",
    "    data = pd.concat([Open, high, low, close, avg_prices,volume,adj_close], axis=1)\n",
    "    data.columns = ['Open', 'high', 'low', 'close', 'avg_prices','volume','adj_close']\n",
    "    #data = data.dropna()\n",
    "    y_train = data['adj_close']\n",
    "    cols = ['Open', 'high', 'low', 'close', 'avg_prices','volume']\n",
    "    X_train = data[cols]\n",
    "    \n",
    "    Open = test_data.open\n",
    "    high = test_data.high\n",
    "    low = test_data.low\n",
    "    close = test_data.close \n",
    "    volume = test_data.volume\n",
    "    avg_prices = test_data.avg_prices\n",
    "    adj_close = test_data.shifted_adj_close\n",
    "    #close_shifted = adj_close.shift(-predicted_days) \n",
    "    data = pd.concat([Open, high, low, close, avg_prices,volume, adj_close], axis=1)\n",
    "    data.columns = ['Open', 'high', 'low', 'close', 'avg_prices','volume','adj_close']\n",
    "    #data = data.dropna()\n",
    "    y_test = data['adj_close']\n",
    "    cols = ['Open', 'high', 'low', 'close', 'avg_prices','volume']\n",
    "    X_test = data[cols]\n",
    "    \n",
    "    scaler_x = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "    X_train = np.array(X_train).reshape((len(X_train),len(cols)))\n",
    "    X_train = scaler_x.fit_transform(X_train)\n",
    "    X_test = np.array(X_test).reshape((len(X_test),len(cols)))\n",
    "    X_test = scaler_x.fit_transform(X_test)\n",
    "    \n",
    "    scaler_y = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "    y_train = np.array(y_train).reshape(len(y_train),1)\n",
    "    y_train = scaler_y.fit_transform(y_train)\n",
    "    y_train = y_train.ravel()\n",
    "    y_test = np.array(y_test).reshape(len(y_test),1)\n",
    "    y_test = scaler_y.fit_transform(y_test)\n",
    "    y_test = y_test.ravel()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(train_data,test_data, predicted_days=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 6)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After running all the below lines, i found out that both models overfit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.99\n",
      "Test set score: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.97\n",
      "Test set score: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model.stochastic_gradient import SGDRegressor\n",
    "cln = SGDRegressor()\n",
    "cln.fit(X_train,y_train)\n",
    "y_pred = cln.predict(X_test)\n",
    "print(\"Training set score: {:.2f}\".format(cln.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(cln.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
